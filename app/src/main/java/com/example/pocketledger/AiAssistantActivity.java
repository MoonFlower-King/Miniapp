package com.example.pocketledger;

import android.Manifest;
import android.content.ActivityNotFoundException;
import android.content.Intent;
import android.content.pm.PackageManager;
import android.os.Bundle;
import android.speech.RecognizerIntent;
import android.widget.EditText;
import android.widget.ImageButton;
import android.widget.Toast;

import androidx.activity.result.ActivityResultLauncher;
import androidx.activity.result.contract.ActivityResultContracts;
import androidx.annotation.NonNull;
import androidx.appcompat.app.AppCompatActivity;
import androidx.core.app.ActivityCompat;
import androidx.core.content.ContextCompat;
import androidx.recyclerview.widget.LinearLayoutManager;
import androidx.recyclerview.widget.RecyclerView;

import java.util.ArrayList;
import java.util.List;
import java.util.Locale;

public class AiAssistantActivity extends AppCompatActivity {

    private static final int PERMISSION_REQUEST_RECORD_AUDIO = 1001;

    private RecyclerView rvChat;
    private EditText etInput;
    private ImageButton btnSend;
    private ImageButton btnVoice;
    private ChatAdapter chatAdapter;
    private List<ChatMessage> messageList = new ArrayList<>();
    private AiManager aiManager;
    private DatabaseHelper dbHelper;

    // Speech recognition using Intent approach (more compatible)
    private ActivityResultLauncher<Intent> speechRecognizerLauncher;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_ai_assistant);

        aiManager = new AiManager();
        dbHelper = DatabaseHelper.getInstance(this);

        initSpeechRecognizerLauncher();
        initViews();
    }

    private void initSpeechRecognizerLauncher() {
        speechRecognizerLauncher = registerForActivityResult(
                new ActivityResultContracts.StartActivityForResult(),
                result -> {
                    if (result.getResultCode() == RESULT_OK && result.getData() != null) {
                        ArrayList<String> matches = result.getData()
                                .getStringArrayListExtra(RecognizerIntent.EXTRA_RESULTS);
                        if (matches != null && !matches.isEmpty()) {
                            String recognizedText = matches.get(0);
                            etInput.setText(recognizedText);
                            etInput.setSelection(recognizedText.length());
                            // Auto send after voice input
                            sendMessage();
                        }
                    }
                });
    }

    private void initViews() {
        findViewById(R.id.btnBack).setOnClickListener(v -> {
            finish();
            overridePendingTransition(R.anim.slide_in_left, R.anim.slide_out_right);
        });
        rvChat = findViewById(R.id.rvChat);
        etInput = findViewById(R.id.etInput);
        btnSend = findViewById(R.id.btnSend);
        btnVoice = findViewById(R.id.btnVoice);

        chatAdapter = new ChatAdapter(messageList,
                // Transaction confirm listener
                (transaction, position) -> {
                    boolean success = dbHelper.addTransaction(transaction);
                    if (success) {
                        Toast.makeText(this, "è´¦å•å·²åˆ›å»º", Toast.LENGTH_SHORT).show();
                        messageList.remove(position);
                        chatAdapter.notifyItemRemoved(position);
                    }
                },
                // Task confirm listener
                (todoItem, position) -> {
                    boolean success = dbHelper.addTodoItem(todoItem);
                    if (success) {
                        Toast.makeText(this, "ä»»åŠ¡å·²åˆ›å»º", Toast.LENGTH_SHORT).show();
                        messageList.remove(position);
                        chatAdapter.notifyItemRemoved(position);
                    }
                });

        rvChat.setLayoutManager(new LinearLayoutManager(this));
        rvChat.setAdapter(chatAdapter);

        btnSend.setOnClickListener(v -> sendMessage());
        btnVoice.setOnClickListener(v -> startVoiceInput());

        // Show welcome message with examples
        showWelcomeMessage();
    }

    private void startVoiceInput() {
        // Check permission first
        if (ContextCompat.checkSelfPermission(this,
                Manifest.permission.RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED) {
            ActivityCompat.requestPermissions(this,
                    new String[] { Manifest.permission.RECORD_AUDIO },
                    PERMISSION_REQUEST_RECORD_AUDIO);
            return;
        }

        // Use Intent-based speech recognition (more compatible across devices)
        Intent intent = new Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH);
        intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM);
        intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.CHINA.toString());
        intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE_PREFERENCE, "zh-CN");
        intent.putExtra(RecognizerIntent.EXTRA_ONLY_RETURN_LANGUAGE_PREFERENCE, true);
        intent.putExtra(RecognizerIntent.EXTRA_PROMPT, "è¯·è¯´è¯...");

        try {
            speechRecognizerLauncher.launch(intent);
        } catch (ActivityNotFoundException e) {
            Toast.makeText(this, "æ‚¨çš„è®¾å¤‡ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œè¯·å®‰è£…è¯­éŸ³è¾“å…¥æ³•", Toast.LENGTH_LONG).show();
        }
    }

    @Override
    public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions,
            @NonNull int[] grantResults) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
        if (requestCode == PERMISSION_REQUEST_RECORD_AUDIO) {
            if (grantResults.length > 0 && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                startVoiceInput();
            } else {
                Toast.makeText(this, "éœ€è¦éº¦å…‹é£æƒé™æ‰èƒ½ä½¿ç”¨è¯­éŸ³è¾“å…¥", Toast.LENGTH_SHORT).show();
            }
        }
    }

    private void showWelcomeMessage() {
        String welcomeText = "ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹\n\n" +
                "æˆ‘å¯ä»¥å¸®ä½ ï¼š\n\n" +
                "ğŸ’° **è®°è´¦** - ç”¨è‡ªç„¶è¯­è¨€è®°å½•æ”¶æ”¯\n" +
                "â€¢ \"åˆé¥­èŠ±äº†35å…ƒ\"\n" +
                "â€¢ \"æ”¶åˆ°å·¥èµ„5000å…ƒ\"\n\n" +
                "âœ… **åˆ›å»ºä»»åŠ¡** - è¯´\"ä»»åŠ¡\"å¼€å¤´\n" +
                "â€¢ \"ä»»åŠ¡ï¼šå®Œæˆä½œä¸šï¼Œæ˜å¤©æˆªæ­¢\"\n" +
                "â€¢ \"ä»»åŠ¡ ç´§æ€¥æäº¤æŠ¥å‘Š\"\n\n" +
                "ğŸ¤ **è¯­éŸ³è¾“å…¥** - ç‚¹å‡»éº¦å…‹é£æŒ‰é’®\n" +
                "ç›´æ¥è¯´è¯ï¼Œæˆ‘ä¼šè½¬æˆæ–‡å­—å¹¶å¤„ç†ï¼";

        ChatMessage welcome = new ChatMessage(ChatMessage.TYPE_AI, welcomeText);
        welcome.setWelcomeMessage(true);
        messageList.add(welcome);
        chatAdapter.notifyItemInserted(0);
    }

    private void sendMessage() {
        String text = etInput.getText().toString().trim();
        if (text.isEmpty())
            return;

        // 1. Add User Message
        messageList.add(new ChatMessage(ChatMessage.TYPE_USER, text));
        chatAdapter.notifyItemInserted(messageList.size() - 1);
        rvChat.scrollToPosition(messageList.size() - 1);
        etInput.setText("");

        // 2. Add AI Thinking Message
        ChatMessage aiMsg = new ChatMessage(ChatMessage.TYPE_AI, "");
        aiMsg.setThinking(true);
        messageList.add(aiMsg);
        int aiPos = messageList.size() - 1;
        chatAdapter.notifyItemInserted(aiPos);
        rvChat.scrollToPosition(aiPos);

        // 3. Determine if this is a task or a bill
        String lowerText = text.toLowerCase();
        boolean isTask = lowerText.startsWith("ä»»åŠ¡") ||
                lowerText.startsWith("æ·»åŠ ä»»åŠ¡") ||
                lowerText.startsWith("æ–°å»ºä»»åŠ¡") ||
                lowerText.startsWith("åˆ›å»ºä»»åŠ¡") ||
                lowerText.contains("ä»»åŠ¡ï¼š") ||
                lowerText.contains("ä»»åŠ¡:");

        if (isTask) {
            // Parse as task
            aiManager.parseTask(text, new AiManager.TaskCallback() {
                @Override
                public void onSuccess(TodoItem todoItem) {
                    aiMsg.setThinking(false);
                    aiMsg.setPendingTodoItem(todoItem);
                    chatAdapter.notifyItemChanged(aiPos);
                }

                @Override
                public void onError(String message) {
                    messageList.remove(aiPos);
                    chatAdapter.notifyItemRemoved(aiPos);
                    Toast.makeText(AiAssistantActivity.this, message, Toast.LENGTH_SHORT).show();
                }
            });
        } else {
            // Parse as bill
            aiManager.parseBill(text, new AiManager.AiCallback() {
                @Override
                public void onSuccess(Transaction transaction) {
                    aiMsg.setThinking(false);
                    aiMsg.setPendingTransaction(transaction);
                    chatAdapter.notifyItemChanged(aiPos);
                }

                @Override
                public void onError(String message) {
                    messageList.remove(aiPos);
                    chatAdapter.notifyItemRemoved(aiPos);
                    Toast.makeText(AiAssistantActivity.this, message, Toast.LENGTH_SHORT).show();
                }
            });
        }
    }
}
